{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports up here, rerun this block when adding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     RatingID   UserID  WineID Vintage  Rating                 Date\n",
      "0        3211  1209683  111478    1959     4.5  2016-08-08 00:50:22\n",
      "1       27878  1209980  111478    1975     4.0  2018-08-12 17:09:39\n",
      "2       31227  1258705  111478    1975     5.0  2014-11-16 19:52:38\n",
      "3       41946  1139706  111478    1979     5.0  2014-12-22 02:30:15\n",
      "4       61700  1240747  111478    1982     4.5  2019-10-21 02:01:10\n",
      "..        ...      ...     ...     ...     ...                  ...\n",
      "995  20871491  1006657  102055    N.V.     3.5  2019-12-29 13:38:44\n",
      "996  20871989  1160496  160271    N.V.     4.0  2015-01-07 12:39:36\n",
      "997  20875704  1055576  102055    N.V.     3.5  2020-11-03 19:14:49\n",
      "998  20885463  1004369  102055    N.V.     3.5  2020-08-29 01:26:13\n",
      "999  20889646  1243678  102055    N.V.     3.5  2019-09-04 18:15:31\n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "    WineID                                  WineName          Type  \\\n",
      "0   100062                             Origem Merlot           Red   \n",
      "1   100191                        Reserva Chardonnay         White   \n",
      "2   101847          Dona Antonia Porto Reserva Tawny  Dessert/Port   \n",
      "3   102055                            Fine Ruby Port  Dessert/Port   \n",
      "4   102079                                 Maré Alta         White   \n",
      "..     ...                                       ...           ...   \n",
      "95  195476  Cuvée Alexander Rose de Pinot Extra Brut     Sparkling   \n",
      "96  195831                            Kormilitsa Red           Red   \n",
      "97  196718                          Select Rosé Brut     Sparkling   \n",
      "98  196838                                  Kallisto         White   \n",
      "99  198580                     The Falcon Pinot Gris         White   \n",
      "\n",
      "           Elaborate                                             Grapes  \\\n",
      "0      Varietal/100%                                         ['Merlot']   \n",
      "1      Varietal/100%                                     ['Chardonnay']   \n",
      "2   Assemblage/Blend  ['Touriga Nacional', 'Touriga Franca', 'Tinta ...   \n",
      "3   Assemblage/Blend  ['Tinta Amarela', 'Tinta Barroca', 'Touriga Fr...   \n",
      "4   Assemblage/Blend                ['Loureiro', 'Alvarinho', 'Arinto']   \n",
      "..               ...                                                ...   \n",
      "95     Varietal/>75%               ['Pinot Noir', 'Cabernet Sauvignon']   \n",
      "96  Assemblage/Blend                   ['Cabernet Sauvignon', 'Limnio']   \n",
      "97  Assemblage/Blend  ['Pinot Blanc', 'Bianca', 'Muscat/Moscato', 'S...   \n",
      "98  Assemblage/Blend                            ['Assyrtiko', 'Robola']   \n",
      "99     Varietal/100%                                     ['Pinot Gris']   \n",
      "\n",
      "                                            Harmonize   ABV  \\\n",
      "0   ['Beef', 'Lamb', 'Veal', 'Grilled', 'Pizza', '...  13.0   \n",
      "1   ['Rich Fish', 'Seafood', 'Risotto', 'Poultry',...  13.0   \n",
      "2       ['Appetizer', 'Sweet Dessert', 'Blue Cheese']  20.0   \n",
      "3   ['Sweet Dessert', 'Cake', 'Fruit', 'Soft Cheese']  19.5   \n",
      "4   ['Fish', 'Shellfish', 'Vegetarian', 'Appetizer...  10.0   \n",
      "..                                                ...   ...   \n",
      "95   ['Appetizer', 'Snack', 'Shellfish', 'Rich Fish']  12.5   \n",
      "96          ['Beef', 'Lamb', 'Spicy Food', 'Poultry']  14.1   \n",
      "97   ['Shellfish', 'Appetizer', 'Snack', 'Lean Fish']  12.5   \n",
      "98  ['Shellfish', 'Lean Fish', 'Poultry', 'Blue Ch...  13.0   \n",
      "99  ['Pork', 'Spicy Food', 'Mushrooms', 'Vegetarian']  13.0   \n",
      "\n",
      "                 Body Acidity Code      Country  RegionID  \\\n",
      "0         Full-bodied  Medium   BR       Brazil      1002   \n",
      "1       Medium-bodied  Medium   BR       Brazil      1001   \n",
      "2    Very full-bodied    High   PT     Portugal      1031   \n",
      "3    Very full-bodied  Medium   PT     Portugal      1031   \n",
      "4   Very light-bodied    High   PT     Portugal      1034   \n",
      "..                ...     ...  ...          ...       ...   \n",
      "95      Medium-bodied    High   RU       Russia      2536   \n",
      "96        Full-bodied  Medium   GR       Greece      2328   \n",
      "97      Medium-bodied    High   RU       Russia      2536   \n",
      "98        Full-bodied    High   GR       Greece      2344   \n",
      "99      Medium-bodied    High   NZ  New Zealand      2485   \n",
      "\n",
      "                                RegionName  WineryID       WineryName  \\\n",
      "0                        Vale dos Vinhedos     10014     Casa Valduga   \n",
      "1                             Serra Gaúcha     10000           Aurora   \n",
      "2                                    Porto     10674   Porto Ferreira   \n",
      "3                                    Porto     10703         Sandeman   \n",
      "4                              Vinho Verde     11486    Fonte Pequena   \n",
      "..                                     ...       ...              ...   \n",
      "95  Taman Peninsula (Таманский полуостров)     60337          Aristov   \n",
      "96                              Chalkidiki     67523         Tsantali   \n",
      "97  Taman Peninsula (Таманский полуостров)     60334  Château Tamagne   \n",
      "98                                    Ilia     67626  Mercouri Estate   \n",
      "99                             Marlborough     69205     Lake Chalice   \n",
      "\n",
      "                                        Website  \\\n",
      "0                 http://www.casavalduga.com.br   \n",
      "1              http://www.vinicolaaurora.com.br   \n",
      "2   https://sogrape.com/pt/brand/porto-ferreira   \n",
      "3                       http://www.sandeman.com   \n",
      "4             https://www.casadafontepequena.pt   \n",
      "..                                          ...   \n",
      "95                       https://aristovwine.ru   \n",
      "96                      http://www.tsantali.com   \n",
      "97                         http://kuban-vino.ru   \n",
      "98                       http://www.mercouri.gr   \n",
      "99                   http://www.lakechalice.com   \n",
      "\n",
      "                                             Vintages  \n",
      "0   [2020, 2019, 2018, 2017, 2016, 2015, 2014, 201...  \n",
      "1   [2021, 2020, 2019, 2018, 2017, 2016, 2015, 201...  \n",
      "2   [2021, 2020, 2019, 2018, 2017, 2016, 2015, 201...  \n",
      "3   [2020, 2019, 2018, 2017, 2016, 2015, 2014, 201...  \n",
      "4   [2022, 2021, 2020, 2019, 2018, 2017, 2016, 201...  \n",
      "..                                                ...  \n",
      "95         [2020, 2019, 2018, 2017, 2016, 2015, 1991]  \n",
      "96  [2021, 2020, 2019, 2018, 2017, 2016, 2015, 201...  \n",
      "97  [2021, 2020, 2019, 2018, 2017, 2016, 2015, 201...  \n",
      "98  [2021, 2020, 2019, 2018, 2017, 2016, 2015, 201...  \n",
      "99  [2021, 2020, 2019, 2018, 2017, 2016, 2015, 201...  \n",
      "\n",
      "[100 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "#assumes dataset in folder\n",
    "wines   = pd.read_csv(\"XWines_Test_100_wines.csv\", low_memory=False, encoding=\"utf-8\", memory_map=True)\n",
    "ratings = pd.read_csv(\"XWines_Test_1K_ratings.csv\", low_memory=False, encoding=\"utf-8\", memory_map=True)\n",
    "len(wines), len(ratings)\n",
    "\n",
    "print(ratings)\n",
    "print(wines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read():\n",
    "    ##assumes dataset in folder\n",
    "    wines   = pd.read_csv(\"XWines_Full_100K_wines.csv\", low_memory=False, encoding=\"utf-8\", memory_map=True)\n",
    "    ratings = pd.read_csv(\"XWines_Full_21M_ratings.csv\", low_memory=False, encoding=\"utf-8\", memory_map=True)\n",
    "    return wines,ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'red' wines in country 'brazil' found with body 'light-bodied'\n",
      "Showing all 'red' wines from country 'brazil' instead.\n",
      "   WineID       WineName Type      Elaborate      Grapes  \\\n",
      "0  100062  Origem Merlot  Red  Varietal/100%  ['Merlot']   \n",
      "\n",
      "                                           Harmonize   ABV         Body  \\\n",
      "0  ['Beef', 'Lamb', 'Veal', 'Grilled', 'Pizza', '...  13.0  Full-bodied   \n",
      "\n",
      "  Acidity Code Country  RegionID         RegionName  WineryID    WineryName  \\\n",
      "0  Medium   BR  Brazil      1002  Vale dos Vinhedos     10014  Casa Valduga   \n",
      "\n",
      "                         Website  \\\n",
      "0  http://www.casavalduga.com.br   \n",
      "\n",
      "                                            Vintages  \n",
      "0  [2020, 2019, 2018, 2017, 2016, 2015, 2014, 201...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "wine_type = input(\"Enter the type of wine (e.g., red, white, rosé, sparkling): \").lower()\n",
    "wine_country = input(\"Enter the country of the wine (e.g., Brazil, New Zealand): \").lower()\n",
    "wine_body = input(\"Enter the body of the wine(e.g. ligth-bodied, medium-bodied, full-bodied): \").lower()\n",
    "\n",
    "filtered_wines = wines.copy()\n",
    "\n",
    "filtered_wines = wines[(wines['Type'].str.lower() == wine_type) \n",
    "                       & (wines['Country'].str.lower() == wine_country)\n",
    "                       & (wines['Body'].str.lower() == wine_body)]\n",
    "\n",
    "if filtered_wines.empty:\n",
    "    filtered_wines = wines[(wines['Type'].str.lower() == wine_type)\n",
    "                           & (wines['Country'].str.lower() == wine_country)]\n",
    "    if not filtered_wines.empty:\n",
    "        print(f\"No '{wine_type}' wines in country '{wine_country}' found with body '{wine_body}'\")\n",
    "        print(f\"Showing all '{wine_type}' wines from country '{wine_country}' instead.\")\n",
    "    else:\n",
    "        filtered_wines = wines[wines['Type'].str.lower() == wine_type]\n",
    "        if not filtered_wines.empty:\n",
    "            print(f\"No '{wine_type}' wines in country '{wine_country}'. Showing all '{wine_type}'instead\")\n",
    "        else:\n",
    "            print(f\"No wines found for the type '{wine_type}'.\")\n",
    "else:\n",
    "    print(f\"Showing '{wine_type}' wines from '{wine_country}'.\")\n",
    "\n",
    "if not filtered_wines.empty:\n",
    "    print(filtered_wines)\n",
    "else:\n",
    "    print(\"No wines found that match your preferences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WineID       WineName Type      Elaborate      Grapes  \\\n",
      "0  100062  Origem Merlot  Red  Varietal/100%  ['Merlot']   \n",
      "\n",
      "                                           Harmonize   ABV         Body  \\\n",
      "0  ['Beef', 'Lamb', 'Veal', 'Grilled', 'Pizza', '...  13.0  Full-bodied   \n",
      "\n",
      "  Acidity Code Country  RegionID         RegionName  WineryID    WineryName  \\\n",
      "0  Medium   BR  Brazil      1002  Vale dos Vinhedos     10014  Casa Valduga   \n",
      "\n",
      "                         Website  \\\n",
      "0  http://www.casavalduga.com.br   \n",
      "\n",
      "                                            Vintages  \n",
      "0  [2020, 2019, 2018, 2017, 2016, 2015, 2014, 201...  \n",
      "     RatingID   UserID  WineID Vintage  Rating                 Date\n",
      "199   2644207  2037611  100062    2010     5.0  2018-07-02 02:32:16\n",
      "554   9655227  1007559  100062    2015     3.5  2017-10-08 01:51:02\n",
      "673  12205871  1261887  100062    2016     3.0  2017-09-15 14:05:08\n",
      "726  13944896  1117421  100062    2016     5.0  2018-10-02 20:54:27\n",
      "728  13980397  1048267  100062    2016     3.5  2020-05-01 10:19:49\n",
      "730  13999921  1195953  100062    2016     3.5  2018-09-05 14:43:04\n",
      "739  14189832  1169598  100062    2017     3.0  2019-07-15 21:21:02\n",
      "754  14578048  1004166  100062    2017     5.0  2019-06-02 16:28:50\n",
      "759  14647910  1163513  100062    2017     3.5  2019-01-19 01:09:54\n",
      "772  14883940  1087116  100062    2017     4.0  2020-02-16 16:59:46\n",
      "   WineID Type Country         Body\n",
      "0  100062  Red  Brazil  Full-bodied\n",
      "   RatingID  WineID   UserID  Rating\n",
      "0   2644207  100062  2037611     5.0\n",
      "1   9655227  100062  1007559     3.5\n",
      "2  12205871  100062  1261887     3.0\n",
      "3  13944896  100062  1117421     5.0\n",
      "4  13980397  100062  1048267     3.5\n",
      "5  13999921  100062  1195953     3.5\n",
      "6  14189832  100062  1169598     3.0\n",
      "7  14578048  100062  1004166     5.0\n",
      "8  14647910  100062  1163513     3.5\n",
      "9  14883940  100062  1087116     4.0\n"
     ]
    }
   ],
   "source": [
    "filtered_reviews = ratings[ratings['WineID'].isin(filtered_wines['WineID'])]\n",
    "\n",
    "# Merge filtered_wines and filtered_reviews on 'WineID'\n",
    "merged_df = pd.merge(filtered_wines, filtered_reviews, on='WineID', how='inner')\n",
    "\n",
    "# Identify columns that belong to the wines and ratings DataFrames\n",
    "wine_columns = ['WineID', 'Type', 'Country', 'Body']  \n",
    "rating_columns = ['RatingID', 'WineID', 'UserID', 'Rating']  \n",
    "\n",
    "# Split the merged DataFrame back into wines and ratings\n",
    "filtered_wines_df = merged_df[wine_columns].drop_duplicates()  # Drop duplicates to get unique wine data\n",
    "filtered_reviews_df = merged_df[rating_columns]\n",
    "\n",
    "print(filtered_wines.head(10))\n",
    "print(filtered_reviews.head(10))\n",
    "print(filtered_wines_df.head(10))\n",
    "print(filtered_reviews_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "def create_wine_features(wine_data):\n",
    "    \"\"\"\n",
    "    Create and combine wine features (textual, categorical, and numerical) from the wine data.\n",
    "    \n",
    "    Args:\n",
    "    - wine_data: DataFrame containing wine feature data.\n",
    "    \n",
    "    Returns:\n",
    "    - wine_features: Sparse matrix of combined wine features (without weights).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a copy of the wine data to avoid modifying the original DataFrame\n",
    "    wine_data = wine_data.copy()\n",
    "\n",
    "    # Preprocessing 'Grapes' and 'Harmonize' columns (convert list to space-separated string)\n",
    "    wine_data['Grapes'] = wine_data['Grapes'].apply(lambda x: ' '.join(eval(x)))\n",
    "    wine_data['Harmonize'] = wine_data['Harmonize'].apply(lambda x: ' '.join(eval(x)))\n",
    "\n",
    "    # Function to handle mixed vintages: list or integer\n",
    "    def convert_to_list(vintages):\n",
    "        if isinstance(vintages, int):\n",
    "            return [str(vintages)] \n",
    "        elif isinstance(vintages, str):\n",
    "            try:\n",
    "                return list(map(str, eval(vintages)))  \n",
    "            except:\n",
    "                return [str(vintages)]  \n",
    "        else:\n",
    "            return [str(vintages)]  \n",
    "\n",
    "    #Apply the conversion to the 'Vintages' column and convert to space-separated string\n",
    "    wine_data['Vintages'] = wine_data['Vintages'].apply(convert_to_list)\n",
    "    wine_data['Vintages'] = wine_data['Vintages'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    #TFIDf vectorization for textual features (Grapes, Harmonize, Vintages)\n",
    "    tfidf = TfidfVectorizer()\n",
    "    wine_data_tfidf_grapes = tfidf.fit_transform(wine_data['Grapes'])\n",
    "    wine_data_tfidf_harmonize = tfidf.fit_transform(wine_data['Harmonize'])\n",
    "    wine_data_tfidf_vintages = tfidf.fit_transform(wine_data['Vintages'])\n",
    "\n",
    "    #One-hot encoding for categorical features ('Type', 'Body', 'Acidity', 'Country', 'RegionName', 'WineryName')\n",
    "    one_hot = OneHotEncoder()\n",
    "    categorical_features = ['Type', 'Body', 'Acidity', 'Country', 'RegionName', 'WineryName']\n",
    "    wine_categorical_onehot = one_hot.fit_transform(wine_data[categorical_features])\n",
    "\n",
    "    #Scale the numerical feature 'ABV'\n",
    "    scaler = StandardScaler()\n",
    "    wine_abv_scaled = scaler.fit_transform(wine_data[['ABV']])\n",
    "\n",
    "    #Combine all features into a single sparse matrix\n",
    "    wine_features = sp.hstack([\n",
    "        wine_data_tfidf_grapes, \n",
    "        wine_data_tfidf_harmonize, \n",
    "        wine_data_tfidf_vintages,\n",
    "        wine_categorical_onehot, \n",
    "        wine_abv_scaled\n",
    "    ]).tocsr()\n",
    "\n",
    "    return (wine_features, wine_categorical_onehot, wine_abv_scaled, \n",
    "            wine_data_tfidf_grapes, wine_data_tfidf_harmonize, wine_data_tfidf_vintages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 46)\t1.0\n",
      "  (0, 99)\t0.21955673571950182\n",
      "  (0, 118)\t0.5408368934756286\n",
      "  (0, 120)\t0.2706022462081998\n",
      "  (0, 126)\t0.34079448462595613\n",
      "  (0, 127)\t0.6098072465339026\n",
      "  (0, 141)\t0.3131436732973766\n",
      "  (0, 197)\t0.3284118925850121\n",
      "  (0, 199)\t0.3353503378267026\n",
      "  (0, 202)\t0.2762869497183293\n",
      "  (0, 203)\t0.2875833615002168\n",
      "  (0, 204)\t0.26814666583970825\n",
      "  (0, 205)\t0.2654927698889014\n",
      "  (0, 206)\t0.2628675652670642\n",
      "  (0, 207)\t0.25264167276101906\n",
      "  (0, 208)\t0.25264167276101906\n",
      "  (0, 209)\t0.24524529196446712\n",
      "  (0, 210)\t0.25264167276101906\n",
      "  (0, 211)\t0.2735430893098887\n",
      "  (0, 212)\t0.2875833615002168\n",
      "  (0, 217)\t1.0\n",
      "  (0, 221)\t1.0\n",
      "  (0, 228)\t1.0\n",
      "  (0, 232)\t1.0\n",
      "  (0, 314)\t1.0\n",
      "  :\t:\n",
      "  (99, 177)\t0.4416644271199072\n",
      "  (99, 181)\t0.43290047476286614\n",
      "  (99, 193)\t0.23105892708301426\n",
      "  (99, 199)\t0.2238535793657743\n",
      "  (99, 200)\t0.21033795139328565\n",
      "  (99, 201)\t0.20607208326024323\n",
      "  (99, 202)\t0.1844274946234303\n",
      "  (99, 203)\t0.1919680929951307\n",
      "  (99, 204)\t0.17899367966116686\n",
      "  (99, 205)\t0.17722214690619034\n",
      "  (99, 206)\t0.175469766231776\n",
      "  (99, 207)\t0.16864376255298805\n",
      "  (99, 208)\t0.16864376255298805\n",
      "  (99, 209)\t0.16370651893370164\n",
      "  (99, 210)\t0.16864376255298805\n",
      "  (99, 211)\t0.1825959086536947\n",
      "  (99, 212)\t0.1919680929951307\n",
      "  (99, 213)\t0.28267824950932047\n",
      "  (99, 220)\t1.0\n",
      "  (99, 223)\t1.0\n",
      "  (99, 226)\t1.0\n",
      "  (99, 239)\t1.0\n",
      "  (99, 282)\t1.0\n",
      "  (99, 385)\t1.0\n",
      "  (99, 423)\t-0.1555334933835019\n"
     ]
    }
   ],
   "source": [
    "(wine_features, wine_categorical_onehot, wine_abv_scaled, \n",
    "        wine_data_tfidf_grapes, wine_data_tfidf_harmonize, wine_data_tfidf_vintages) = create_wine_features(wines)\n",
    "\n",
    "print(wine_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = filtered_reviews['Rating'].values\n",
    "x_train = []\n",
    "\n",
    "for index, row in ratings.iterrows():\n",
    "    user_ID = row['UserID']\n",
    "    wine_ID = row['WineID']\n",
    "    wine_index = wines.index[wines['WineID'] == wine_ID].tolist()[0]\n",
    "    wine_feature = wine_features[wine_index]\n",
    "    x_train.append(wine_feature)\n",
    "\n",
    "x_train = sp.vstack(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'CB_similarities.CBRecommender'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 21]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m svr_model \u001b[38;5;241m=\u001b[39m make_pipeline(StandardScaler(), SVR(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Fit the SVR model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43msvr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_csr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to dense for SVR fitting\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVR model has been fitted.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# To make predictions (optional)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alexa VT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alexa VT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 427\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Alexa VT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alexa VT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Alexa VT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Alexa VT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1164\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\Alexa VT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 21]"
     ]
    }
   ],
   "source": [
    "from CB_similarities import CBRecommender\n",
    "from CB import ContentBasedRecommender\n",
    "\n",
    "print(CBRecommender)\n",
    "\n",
    "recommender = ContentBasedRecommender(filtered_reviews, filtered_wines)\n",
    "\n",
    "x_train_dense = x_train.toarray()\n",
    "x_train_df = pd.DataFrame(x_train_dense)\n",
    "print(x_train_df.head(5))\n",
    "\n",
    "recommender.fit(x_train_df)\n",
    "\n",
    "# choose a userID from the above filtered_reviews df\n",
    "recommendations = recommender.recommend(1138214, top_n=5)\n",
    "print('These recommended wines are similar based on your Type, Country and Body preferences: ')\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCB_similarities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CBRecommender\n\u001b[1;32m----> 2\u001b[0m train_ratings, test_ratings \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(ratings, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m recommender \u001b[38;5;241m=\u001b[39m CBRecommender(train_ratings, wines)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_ratings\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "from CB_similarities import CBRecommender\n",
    "train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "recommender = CBRecommender(train_ratings, wines)\n",
    "print(train_ratings.shape)\n",
    "print(wines.shape)\n",
    "recommender.fit()\n",
    "\n",
    "user_ids = test_ratings['UserID'].drop_duplicates()\n",
    "\n",
    "# Store evaluation metrics\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Iterate through each user in the test set\n",
    "for user_id in user_ids:\n",
    "\n",
    "    # Your processing code for each user_id goes here\n",
    "    # Generate recommendations for the user\n",
    "    recommendations = recommender.recommend(user_id, top_n=5)\n",
    "\n",
    "    if not recommendations:\n",
    "        print(f\"No recommendations for User {user_id}\")\n",
    "        continue\n",
    "\n",
    "    # Define relevant wines based on the test ratings for the user\n",
    "    threshold = 3\n",
    "    relevant_wines = set(test_ratings[(test_ratings['UserID'] == user_id) & \n",
    "                                  (test_ratings['Rating'] >= threshold)]['WineID'])\n",
    "    # print(\"Relevant wines: \" + str(relevant_wines))\n",
    "    \n",
    "    # Extract the recommended wine IDs\n",
    "    recommended_wine_ids = set(recommendations)\n",
    "    # print(\"Recommended Wines: \" + str(recommended_wine_ids))\n",
    "    # Calculate True Positives, False Positives, and False Negatives\n",
    "    true_positives = len(relevant_wines.intersection(recommended_wine_ids))\n",
    "    false_positives = len(recommended_wine_ids - relevant_wines)\n",
    "    false_negatives = len(relevant_wines - recommended_wine_ids)\n",
    "\n",
    "    # Calculate Precision, Recall, and F1 Score\n",
    "    if (true_positives + false_positives) > 0:\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "    else:\n",
    "        precision = 0.0  # Avoid division by zero\n",
    "\n",
    "    if (true_positives + false_negatives) > 0:\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "    else:\n",
    "        recall = 0.0  # Avoid division by zero\n",
    "\n",
    "    if (precision + recall) > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0.0  # Avoid division by zero\n",
    "\n",
    "    # Store the metrics for each user\n",
    "    # print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "\n",
    "avg_precision = sum(precision_list) / len(precision_list) if precision_list else 0.0\n",
    "avg_recall = sum(recall_list) / len(recall_list) if recall_list else 0.0\n",
    "avg_f1 = sum(f1_list) / len(f1_list) if f1_list else 0.0\n",
    "\n",
    "print(f\"Average Precision: {avg_precision}\")\n",
    "print(f\"Average Recall: {avg_recall}\")\n",
    "print(f\"Average F1 Score: {avg_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
